<html>
  <head>
    <link rel=stylesheet href="style.css" type="text/css">
    <title>jfKVM</title>
  </head>
  <body>
  <div class=title>
    <div class=title_content_center>jfKVM : Storage</div>
  </div>
  <div class=content>

<pre>

CephFS Storage:
===============

Desc:
-----
Replicated file system for storage pools (Red Hat) (vSAN).

Requirements:
-------------

Three or more servers in a cluster.
Each server has available disks.

Instructions:
-------------

First go to the <a href="help_cluster.html">Cluster</a> screen and connect all hosts to each other.

On each node go to settings and ensure Storage IP is configured.

Perform a 'Ceph Setup' on one of the servers.

On each server add a new storage pool, selecting CephFS and provide a pool name.
The ceph pool must be Started and Mounted on each server.

Recommended:
------------

A third network interface (10GB+) should be used.  
Create a bridge on the interface and a virtual server interface on the bridge.  
Or configure the switch where this physical interface resides with a native VLAN on desired VLAN.
In the server settings screen set the Storage IP to this server interface IP address.
This will allow you to place the ceph traffic on its own VLAN.

Ceph CLI:
---------

View Status:
  ceph status

View available disks:
  ceph orch device ls

Zap disk:
  ceph orch device zap {host} {device} --force

Add all available disks:
  ceph orch apply osd --all-available-devices  

Notes:
------
 - if the initial setup missed some disks, you can zap them and then re-add them.

</pre>
<br><br>

<a href="http://sourceforge.net/projects/jfkvm">Project Page</a>
 <img valign="center" src="/img/vr.gif" width=2 height=12>
<a href="help.html">Help</a>
 <img valign="center" src="/img/vr.gif" width=2 height=12>
<a href="https://github.com/pquiring/javaforce/tree/master/projects/jfkvm">GitHub</a>

</pre>
<br><br>

<!--  </div>  -->
  </body>
</html>

<script type="text/javascript" src="/style.js"></script>
